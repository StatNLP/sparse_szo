{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert tensorboard's event file to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "from collections import defaultdict\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(dfs):\n",
    "    return reduce(lambda left, right: pd.merge(left, right, how='outer',\n",
    "                                       left_index=True, right_index=True), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def events2csv(glob_path, save=True):\n",
    "    head, tail = os.path.split(glob_path)\n",
    "    summary_iterator = EventAccumulator(glob_path).Reload()\n",
    "    tags = summary_iterator.Tags()['scalars']\n",
    "    dfs = []\n",
    "\n",
    "    for tag in tags:\n",
    "        steps = [e.step for e in summary_iterator.Scalars(tag)]\n",
    "        values = [e.value for e in summary_iterator.Scalars(tag)]\n",
    "        \n",
    "        df = pd.DataFrame(values, index=steps, columns=[tag.replace('/', '_')])\n",
    "        dfs.append(df)\n",
    "\n",
    "    df_joined = merge(dfs)\n",
    "    if save:\n",
    "        df_joined.to_csv(f'{head}-results.csv', index=True, index_label='steps')\n",
    "    return df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'train_cuml_reward_nce',\n",
    "    'test_acc',\n",
    "    'test_neighbourhood_0.01',\n",
    "    'test_neighbourhood_0.02',\n",
    "    'test_neighbourhood_0.05',\n",
    "    'test_neighbourhood_0.1',\n",
    "    'test_neighbourhood_0.5',\n",
    "    'test_gradient_norm_true',\n",
    "    'util_gradient_norm_true',\n",
    "    'util_gradient_norm_approx',\n",
    "    'util_lipschitz_t-1_t',\n",
    "    'util_lipschitz_t-1_t_numerator',\n",
    "    'util_lipschitz_t-1_t_denominator',\n",
    "    'util_lipschitz',\n",
    "    'util_lipschitz_numerator',\n",
    "    'util_lipschitz_denominator',\n",
    "    'util_lipschitz_f-mu_f',\n",
    "    'util_lipschitz_f-mu_f_numerator'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_map = {\n",
    "    'train_cuml_reward_nce': 'train_cuml_reward_nce',\n",
    "    'test_acc': 'test_acc',\n",
    "    'test_neighbourhood_0.01': 'test_neighbourhood_0.01',\n",
    "    'test_neighbourhood_0.02': 'test_neighbourhood_0.02',\n",
    "    'test_neighbourhood_0.05': 'test_neighbourhood_0.05',\n",
    "    'test_neighbourhood_0.1': 'test_neighbourhood_0.1',\n",
    "    'test_neighbourhood_0.5': 'test_neighbourhood_0.5',\n",
    "    'test_gradient_norm_true': 'test_gradient_norm_true',\n",
    "    'util_gradient_norm_true': 'util_gradient_norm_true',\n",
    "    'util_gradient_norm_approx': 'util_gradient_norm_approx',\n",
    "    'util_lipschitz_t-1_t': 'util_lipschitz_t-1_t',\n",
    "    'util_lipschitz_t-1_t_numerator': 'util_lipschitz_t-1_t_numerator',\n",
    "    'util_lipschitz_t-1_t_denominator': 'util_lipschitz_t-1_t_denominator',\n",
    "    'util_lipschitz': 'util_lipschitz',\n",
    "    'util_lipschitz_numerator': 'util_lipschitz_numerator',\n",
    "    'util_lipschitz_denominator': 'util_lipschitz_denominator',\n",
    "    'util_lipschitz_f-mu_f': 'util_lipschitz_f-mu_f',\n",
    "    'util_lipschitz_f-mu_f_numerator': 'util_lipschitz_f-mu_f_numerator',\n",
    "    'lipschitz_neighbourhood_0.01_test': 'test_neighbourhood_0.01',\n",
    "    'lipschitz_neighbourhood_0.02_test': 'test_neighbourhood_0.02',\n",
    "    'lipschitz_neighbourhood_0.05_test': 'test_neighbourhood_0.05',\n",
    "    'lipschitz_neighbourhood_0.1_test': 'test_neighbourhood_0.1',\n",
    "    'lipschitz_neighbourhood_0.5_test': 'test_neighbourhood_0.5',\n",
    "    'gradients_norm_true_test': 'test_gradient_norm_true',\n",
    "    'gradients_norm_true_train': 'util_gradient_norm_true',\n",
    "    'gradients_norm_approx_train': 'util_gradient_norm_approx',\n",
    "    'lipschitz_t-1_t': 'util_lipschitz_t-1_t',\n",
    "    'lipschitz_t-1_t_numerator': 'util_lipschitz_t-1_t_numerator',\n",
    "    'lipschitz_t-1_t_denominator': 'util_lipschitz_t-1_t_denominator',\n",
    "    'lipschitz_global': 'util_lipschitz',\n",
    "    'lipschitz_global_numerator': 'util_lipschitz_numerator',\n",
    "    'lipschitz_global_denominator': 'util_lipschitz_denominator',\n",
    "    'lipschitz_f-mu_f': 'util_lipschitz_f-mu_f',\n",
    "    'lipschitz_f-mu_f_numerator': 'util_lipschitz_f-mu_f_numerator'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'prune-last-L1',\n",
    "    'prune-last-random',\n",
    "    'freeze-last-L1',\n",
    "    'freeze-last-random',\n",
    "    'none-last-none'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    'MNIST': ([31, 32, 33], 64),\n",
    "    'CIFAR-10': ([404, 414, 424], 64)\n",
    "}\n",
    "results = {\n",
    "    'MNIST': {},\n",
    "    'CIFAR-10': {}\n",
    "}\n",
    "\n",
    "for key, (seeds, batch_size) in runs.items():\n",
    "    data = {}\n",
    "    for seed in seeds:# + cifar_seed:\n",
    "        dfs = {}\n",
    "        for label in labels:\n",
    "            glob_path = glob.glob(f\"../runs-{seed}/agarwal-nce-{label}-{batch_size}/events.out*\")\n",
    "            assert len(glob_path) == 1, (glob_path)\n",
    "            dfs[label] = events2csv(glob_path[0], save=False)\n",
    "\n",
    "        cols = {}\n",
    "        for col_key, col in col_map.items():\n",
    "            if col_key in dfs[label].columns:\n",
    "                cols[col] = merge([dfs[label][col_key].to_frame(label) for label in labels])\n",
    "                assert len(cols[col].columns) == len(labels)\n",
    "        data[seed] = cols\n",
    "        \n",
    "    results[key] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(scalars, factor=0.8): # 0 < factor < 1\n",
    "    prev = None if np.isnan(scalars[0]) else scalars[0] # First value in the plot (first timestep)\n",
    "    smoothed = list()\n",
    "    for current in scalars:\n",
    "        if np.isnan(current):\n",
    "            smoothed.append(float('nan'))\n",
    "            continue\n",
    "        else:\n",
    "            if prev is None:\n",
    "                prev = current\n",
    "            smoothed_val = prev * factor + current * (1 - factor) # Calculate smoothed value\n",
    "            smoothed.append(smoothed_val)                       # Save it\n",
    "            prev = smoothed_val                                 # Anchor the last smoothed value\n",
    "    assert len(scalars) == len(smoothed), (len(scalars), len(smoothed))\n",
    "    assert sum([1 for i in scalars if np.isnan(i)]) == sum([1 for i in smoothed if np.isnan(i)])\n",
    "    return np.array(smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylabel_map = {\n",
    "    'train_cuml_reward_nce': 'Cross Entropy $f(\\mathbf{w}^{(t)})$',\n",
    "    'test_acc': 'Test Accuracy',\n",
    "    'test_neighbourhood_0.01': r'Lipschitz smoothness $L_\\mathrm{neighbor}(0.01)$',\n",
    "    'test_neighbourhood_0.02': r'Lipschitz smoothness $L_\\mathrm{neighbor}(0.02)$',\n",
    "    'test_neighbourhood_0.05': r'Lipschitz smoothness $L_\\mathrm{neighbor}(0.05)$',\n",
    "    'test_neighbourhood_0.1': r'Lipschitz smoothness $L_\\mathrm{neighbor}(0.1)$',\n",
    "    'test_neighbourhood_0.5': r'Lipschitz smoothness $L_\\mathrm{neighbor}(0.5)$',\n",
    "    'test_gradient_norm_true': r'True Gradient Norm $ || \\nabla f(\\mathbf{w}^{(t)}) ||^2 $',\n",
    "    'util_gradient_norm_true': r'True Gradient Norm $ || \\nabla f(\\mathbf{w}^{(t)}) ||^2 $',\n",
    "    'util_gradient_norm_approx': r'Approx Gradient Norm $ || g_\\mu(\\mathbf{w}^{(t)}) ||^2 $',\n",
    "    'util_lipschitz_t-1_t': r'Lipschitz smoothness $L_\\mathrm{local}$',\n",
    "    'util_lipschitz_t-1_t_numerator': r'Numerator $ || \\nabla f(\\mathbf{w}^{(t-1)}) - \\nabla f(\\mathbf{w}^{(t)}) || $',\n",
    "    'util_lipschitz_t-1_t_denominator': r'Denominator $ ||\\mathbf{w}^{(t-1)} - \\mathbf{w}^{(t)}|| $',\n",
    "    'util_lipschitz': r'Lipschitz smoothness $L_\\mathrm{global}$',\n",
    "    'util_lipschitz_numerator': r'Numerator $ || \\nabla f(\\mathbf{w}^{(i)}) - \\nabla f(\\mathbf{w}^{(j)}) ||^2 $',\n",
    "    'util_lipschitz_denominator': r'Denominator $ ||\\mathbf{w}^{(i)} - \\mathbf{w}^{(j)}|| $',\n",
    "    'util_lipschitz_f-mu_f': r'Lipschitz smoothness $L_{\\mathrm{true}-\\mathrm{approx}}$',\n",
    "    'util_lipschitz_f-mu_f_numerator': r'$|| \\nabla f_{\\mu}(\\mathbf{w}^{(t)}) - \\nabla f(\\mathbf{w}^{(t)}) ||^2$'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_map = {\n",
    "    'freeze-last-L1': 'freezing magnitude-masking',\n",
    "    'freeze-last-random': 'freezing random-masking',\n",
    "    'prune-last-L1': 'pruning magnitude-masking',\n",
    "    'prune-last-random': 'pruning random-masking',\n",
    "    'none-last-none': 'dense'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_color_map = {\n",
    "    'none-last-none': 'tab:green', #'#2ca02c',\n",
    "    'prune-last-L1': 'tab:blue', #'#1f77b4',\n",
    "    'freeze-last-L1': 'tab:red', #'#d62728',\n",
    "    'prune-last-random': 'tab:purple', #'#9467bd',\n",
    "    'freeze-last-random': 'tab:orange' #'#ff7f0e'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams, font_manager\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['DejaVu Sans', 'Helvetica', 'Tahoma', \n",
    "                               'Lucida Grande', 'Verdana']\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot(df, plt, fig, ax, col, data_name, data_size, model_size):\n",
    "    \n",
    "    x = pd.to_numeric(df.index.values, downcast='integer')\n",
    "    \n",
    "    for tag in labels:\n",
    "        if f'{tag}_mean' not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        y = pd.to_numeric(df[f'{tag}_mean'].values)\n",
    "        y_std = pd.to_numeric(df[f'{tag}_std'].values)\n",
    "        \n",
    "        kwargs = {'linestyle': '-', 'linewidth': 3.0}\n",
    "        if 'prune' in tag:\n",
    "            kwargs['linestyle'] = '--'\n",
    "            kwargs['dashes'] = (3, 3)\n",
    "        elif 'none' in tag:\n",
    "            kwargs['linestyle'] = ':'\n",
    "            #kwargs['dashes'] = (5, 5)\n",
    "        ax.plot(x/1000, y, c=tag_color_map[tag], label=legend_map[tag], **kwargs)\n",
    "        ax.fill_between(x/1000, y - y_std, y + y_std, alpha=0.2, color=tag_color_map[tag])\n",
    "    \n",
    "    ax.set_title(data_name, fontsize='20', fontweight=\"bold\")\n",
    "    axR = ax.twiny()\n",
    "    \n",
    "    t = 20 # number of rounds\n",
    "    e = 5 # number of epochs\n",
    "    k = int((data_size/1000)) * e # 50*5 for mnist, 40*5 for cifar\n",
    "    ax.tick_params(direction = 'out')\n",
    "    xprint = np.arange(0, k*t+1, k)\n",
    "    ax.set_xticks(np.arange(0, k*t+1, k))\n",
    "    ax.set_xlabel('Number of Examples', fontsize=20)\n",
    "    ax.set_xlim((-100, k*t+100))\n",
    "    ax.set_xticklabels(['{:3d}k'.format(s) if i%2 == 0 else '' for i, s in enumerate(xprint)], fontsize=16)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    ax.set_ylabel(ylabel_map[col], fontsize=20)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    \n",
    "    if data_name=='MNIST':\n",
    "        #if 'test_gradient_norm_true' in col:\n",
    "        #    ax.set_ylim((-0.1, 2.1))\n",
    "        if 'test_acc' in col:\n",
    "            ax.set_ylim((0.45, 0.95))\n",
    "        #elif 'util_gradient_norm_true' in col:\n",
    "        #    ax.set_ylim((-0.1, 5.1))\n",
    "        elif 'util_gradient_norm_approx' in col:\n",
    "            ax.set_ylim((-0.1, 5.1))\n",
    "        #elif 'util_lipschitz_f-mu_f_numerator' in col:\n",
    "        #    ax.set_ylim((-0.1, 5.1))\n",
    "        elif 'neighbourhood_0.01' in col:\n",
    "            ax.set_ylim((-0.1, 2.1))\n",
    "        elif 'neighbourhood_0.02' in col:\n",
    "            ax.set_ylim((-0.1, 2.1))\n",
    "        elif 'neighbourhood_0.05' in col:\n",
    "            ax.set_ylim((-1, 11))\n",
    "        elif 'neighbourhood_0.1' in col:\n",
    "            ax.set_ylim((-1, 11))\n",
    "        elif 'neighbourhood_0.5' in col:\n",
    "            ax.set_ylim((-1, 41))\n",
    "    elif data_name=='CIFAR-10':\n",
    "        #if 'test_gradient_norm_true' in col:\n",
    "        #    ax.set_ylim((-1, 5))\n",
    "        #if 'util_gradient_norm_true' in col:\n",
    "        #    ax.set_ylim((-1, 5))\n",
    "        if 'neighbourhood_0.01' in col:\n",
    "            ax.set_ylim((-0.1, 2.1))\n",
    "        elif 'neighbourhood_0.02' in col:\n",
    "            ax.set_ylim((-0.1, 2.1))\n",
    "        elif 'neighbourhood_0.05' in col:\n",
    "            ax.set_ylim((-1, 11))\n",
    "        elif 'neighbourhood_0.1' in col:\n",
    "            ax.set_ylim((-1, 11))\n",
    "        elif 'neighbourhood_0.5' in col:\n",
    "            ax.set_ylim((-10, 1010))\n",
    "        \n",
    "    \n",
    "    axR.tick_params(direction = 'in')\n",
    "    xtick_top = [0.0]\n",
    "    xtick_dummy = [model_size] # 266610 for mnist, 4301642 for cifar\n",
    "    for i in range(t):\n",
    "        a = xtick_dummy[-1] - (xtick_dummy[-1] * 0.2)\n",
    "        s = 1 - (a / xtick_dummy[0])\n",
    "        #print(s, a, xtick_dummy[0])\n",
    "        xtick_top.append(s)\n",
    "        xtick_dummy.append(a)\n",
    "    axR.set_xticks(np.arange(0, k*t+1, k))\n",
    "    axR.set_xticklabels(['{0:.3f}'.format(s) if i%2 == 0 else '' for i, s in enumerate(xtick_top)], fontsize=16)\n",
    "    axR.set_xlabel('Sparsity', fontsize = 20)\n",
    "    axR.set_xlim((-100, k*t+100))\n",
    "    \n",
    "    plt.xticks(fontname='DejaVu Sans', fontsize=16)\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(mnist, cifar, col):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(24, 6), dpi=200) #, dpi=300\n",
    "\n",
    "    plt = subplot(mnist, plt, fig, ax[0], col, 'MNIST', 50000, 266610)\n",
    "    plt = subplot(cifar, plt, fig, ax[1], col, 'CIFAR-10', 40000, 4301642)\n",
    "    #print(lines)\n",
    "    #print(linelabels)\n",
    "    handles, linelabels = ax[0].get_legend_handles_labels()\n",
    "    #linelabels = ['\\n'.join(l.split(' ')) for l in sorted(linelabels, reverse=True)]\n",
    "    lgd = fig.legend(handles, linelabels, loc='lower center',\n",
    "               fontsize=18, bbox_to_anchor=(0.48, -0.005), ncol=5) #labelspacing=0.5\n",
    "    fig.subplots_adjust(bottom=0.2, left=-0.05)\n",
    "    return plt, lgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dfs(data_name, col): #\n",
    "    data = results[data_name]\n",
    "    dfs_tag = []\n",
    "    for tag in labels:\n",
    "        dfs_seeds = []\n",
    "        seeds, batch_size = runs[data_name]\n",
    "        for seed in seeds:\n",
    "            if col not in data[seed].keys():\n",
    "                continue\n",
    "            c = data[seed][col][tag]\n",
    "            c_index = c.index\n",
    "            if 'nce' in col:\n",
    "                c = c.apply(lambda y: -y)\n",
    "            elif 'norm' in col:\n",
    "                c = pd.Series(interpolate(c.values, factor=interpolation))\n",
    "            elif 'lipschitz' in col:\n",
    "                if 'f-mu_f_numerator' in col:\n",
    "                    c = np.power(c.values, 2)\n",
    "                else:\n",
    "                    c = c.values\n",
    "                c = pd.Series(interpolate(c, factor=interpolation))\n",
    "            dfs_seeds.append(c.to_frame(f'runs-{seed}').set_index([c_index]))\n",
    "        if len(dfs_seeds) > 0:\n",
    "            df = merge(dfs_seeds)\n",
    "            df_mean = df.mean(axis=1).to_frame(f'{tag}_mean')\n",
    "            df_mean[f'{tag}_std'] = df.std(axis=1)\n",
    "            dfs_tag.append(df_mean)\n",
    "    df_mean_std = merge(dfs_tag)\n",
    "    return df_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in columns:\n",
    "    mnist_df = prepare_dfs('MNIST', col)\n",
    "    cifar_df = prepare_dfs('CIFAR-10', col)\n",
    "    \n",
    "    print(col)\n",
    "    if 'norm' in col:\n",
    "        print('interpolation', interpolation)\n",
    "    elif 'lipschitz' in col:\n",
    "        print('interpolation', interpolation)\n",
    "    plt, lgd = plot(mnist_df, cifar_df, col)\n",
    "    col = col.replace('.', '')\n",
    "    plt.savefig(f'szo-results-new-{col}.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
